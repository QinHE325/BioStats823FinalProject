{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heqin\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    " \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 2\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heqin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "datagen.fit(X_train)\n",
    "history_simple = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)\n",
    "history_aug = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "def plot_hist(history):\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "    ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample_data = 3000\n",
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\").sample(num_sample_data)\n",
    "test = pd.read_csv(\"test.csv\").sample(num_sample_data)\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 2\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13027    0\n",
       "21160    3\n",
       "28354    6\n",
       "2911     8\n",
       "38600    0\n",
       "        ..\n",
       "5286     7\n",
       "15783    2\n",
       "40014    7\n",
       "30388    8\n",
       "8241     0\n",
       "Name: label, Length: 2700, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 - 3s - loss: 1.8281 - accuracy: 0.3778 - val_loss: 1.1644 - val_accuracy: 0.6200 - 3s/epoch - 170ms/step\n",
      "Epoch 2/20\n",
      "18/18 - 2s - loss: 0.7517 - accuracy: 0.7578 - val_loss: 0.4515 - val_accuracy: 0.8900 - 2s/epoch - 107ms/step\n",
      "Epoch 3/20\n",
      "18/18 - 2s - loss: 0.4040 - accuracy: 0.8678 - val_loss: 0.3664 - val_accuracy: 0.8900 - 2s/epoch - 110ms/step\n",
      "Epoch 4/20\n",
      "18/18 - 2s - loss: 0.3708 - accuracy: 0.8889 - val_loss: 0.3267 - val_accuracy: 0.9100 - 2s/epoch - 113ms/step\n",
      "Epoch 5/20\n",
      "18/18 - 2s - loss: 0.2191 - accuracy: 0.9311 - val_loss: 0.3542 - val_accuracy: 0.9100 - 2s/epoch - 105ms/step\n",
      "Epoch 6/20\n",
      "18/18 - 2s - loss: 0.1752 - accuracy: 0.9400 - val_loss: 0.2713 - val_accuracy: 0.9200 - 2s/epoch - 103ms/step\n",
      "Epoch 7/20\n",
      "18/18 - 2s - loss: 0.1577 - accuracy: 0.9567 - val_loss: 0.3213 - val_accuracy: 0.9100 - 2s/epoch - 118ms/step\n",
      "Epoch 8/20\n",
      "18/18 - 2s - loss: 0.1399 - accuracy: 0.9567 - val_loss: 0.2883 - val_accuracy: 0.9200 - 2s/epoch - 112ms/step\n",
      "Epoch 9/20\n",
      "18/18 - 2s - loss: 0.1111 - accuracy: 0.9611 - val_loss: 0.3487 - val_accuracy: 0.9100 - 2s/epoch - 121ms/step\n",
      "Epoch 10/20\n",
      "18/18 - 2s - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.3938 - val_accuracy: 0.9300 - 2s/epoch - 112ms/step\n",
      "Epoch 11/20\n",
      "18/18 - 2s - loss: 0.0782 - accuracy: 0.9744 - val_loss: 0.3568 - val_accuracy: 0.9300 - 2s/epoch - 116ms/step\n",
      "Epoch 12/20\n",
      "18/18 - 2s - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.3261 - val_accuracy: 0.9300 - 2s/epoch - 113ms/step\n",
      "Epoch 13/20\n",
      "18/18 - 2s - loss: 0.0596 - accuracy: 0.9822 - val_loss: 0.3825 - val_accuracy: 0.9400 - 2s/epoch - 112ms/step\n",
      "Epoch 14/20\n",
      "18/18 - 2s - loss: 0.0508 - accuracy: 0.9867 - val_loss: 0.3193 - val_accuracy: 0.9300 - 2s/epoch - 116ms/step\n",
      "Epoch 15/20\n",
      "18/18 - 2s - loss: 0.0539 - accuracy: 0.9867 - val_loss: 0.2562 - val_accuracy: 0.9400 - 2s/epoch - 112ms/step\n",
      "Epoch 16/20\n",
      "18/18 - 2s - loss: 0.0279 - accuracy: 0.9900 - val_loss: 0.3915 - val_accuracy: 0.9300 - 2s/epoch - 116ms/step\n",
      "Epoch 17/20\n",
      "18/18 - 2s - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.3820 - val_accuracy: 0.9300 - 2s/epoch - 113ms/step\n",
      "Epoch 18/20\n",
      "18/18 - 2s - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.3171 - val_accuracy: 0.9200 - 2s/epoch - 117ms/step\n",
      "Epoch 19/20\n",
      "18/18 - 2s - loss: 0.0327 - accuracy: 0.9922 - val_loss: 0.2910 - val_accuracy: 0.9400 - 2s/epoch - 114ms/step\n",
      "Epoch 20/20\n",
      "18/18 - 2s - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.4106 - val_accuracy: 0.9300 - 2s/epoch - 108ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heqin\\AppData\\Local\\Temp/ipykernel_2988/281973051.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_aug = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 3s - loss: 0.5932 - accuracy: 0.8378 - val_loss: 0.2233 - val_accuracy: 0.9300 - lr: 0.0010 - 3s/epoch - 146ms/step\n",
      "Epoch 2/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.3754 - accuracy: 0.8878 - val_loss: 0.2181 - val_accuracy: 0.9300 - lr: 0.0010 - 2s/epoch - 107ms/step\n",
      "Epoch 3/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.3697 - accuracy: 0.8944 - val_loss: 0.1830 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 110ms/step\n",
      "Epoch 4/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.2375 - accuracy: 0.9256 - val_loss: 0.2376 - val_accuracy: 0.9500 - lr: 0.0010 - 2s/epoch - 112ms/step\n",
      "Epoch 5/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.2498 - accuracy: 0.9178 - val_loss: 0.1585 - val_accuracy: 0.9500 - lr: 0.0010 - 2s/epoch - 117ms/step\n",
      "Epoch 6/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.2782 - accuracy: 0.9156 - val_loss: 0.1485 - val_accuracy: 0.9700 - lr: 0.0010 - 2s/epoch - 122ms/step\n",
      "Epoch 7/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1999 - accuracy: 0.9422 - val_loss: 0.1650 - val_accuracy: 0.9500 - lr: 0.0010 - 2s/epoch - 117ms/step\n",
      "Epoch 8/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.2476 - accuracy: 0.9233 - val_loss: 0.1308 - val_accuracy: 0.9700 - lr: 0.0010 - 2s/epoch - 128ms/step\n",
      "Epoch 9/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1696 - accuracy: 0.9400 - val_loss: 0.1472 - val_accuracy: 0.9600 - lr: 0.0010 - 2s/epoch - 125ms/step\n",
      "Epoch 10/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1768 - accuracy: 0.9411 - val_loss: 0.1676 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 119ms/step\n",
      "Epoch 11/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1404 - accuracy: 0.9544 - val_loss: 0.1887 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 118ms/step\n",
      "Epoch 12/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1895 - accuracy: 0.9378 - val_loss: 0.1433 - val_accuracy: 0.9700 - lr: 0.0010 - 2s/epoch - 108ms/step\n",
      "Epoch 13/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1676 - accuracy: 0.9522 - val_loss: 0.1642 - val_accuracy: 0.9500 - lr: 0.0010 - 2s/epoch - 112ms/step\n",
      "Epoch 14/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1225 - accuracy: 0.9633 - val_loss: 0.1930 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 113ms/step\n",
      "Epoch 15/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1814 - accuracy: 0.9500 - val_loss: 0.1622 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 117ms/step\n",
      "Epoch 16/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1461 - accuracy: 0.9489 - val_loss: 0.1404 - val_accuracy: 0.9500 - lr: 0.0010 - 2s/epoch - 128ms/step\n",
      "Epoch 17/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1041 - accuracy: 0.9733 - val_loss: 0.1380 - val_accuracy: 0.9600 - lr: 0.0010 - 2s/epoch - 139ms/step\n",
      "Epoch 18/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1131 - accuracy: 0.9656 - val_loss: 0.1259 - val_accuracy: 0.9600 - lr: 0.0010 - 2s/epoch - 128ms/step\n",
      "Epoch 19/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1308 - accuracy: 0.9544 - val_loss: 0.1653 - val_accuracy: 0.9400 - lr: 0.0010 - 2s/epoch - 124ms/step\n",
      "Epoch 20/20\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "18/18 - 2s - loss: 0.1105 - accuracy: 0.9644 - val_loss: 0.1308 - val_accuracy: 0.9600 - lr: 0.0010 - 2s/epoch - 121ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "datagen.fit(X_train)\n",
    "history_simple = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)\n",
    "history_aug = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n",
    "%reload_ext tensorboard\n",
    "import datetime\n",
    "log_folder = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "log_folder = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "callbacks = [TensorBoard(log_dir=log_folder,\n",
    "                         histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_images=True,\n",
    "                         update_freq='epoch',\n",
    "                         profile_batch=2,\n",
    "                         embeddings_freq=1)]\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33328/3954776684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(X_train, Y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           callbacks=callbacks)\n",
      "\u001b[1;32mc:\\Users\\heqin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heqin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorboard\n",
    "plot_model(model, to_file=\"my_model.png\", show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "087536d2f226a480f9bd90cd8588d19e153847dd2406d6dabc3f28f64513666f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
